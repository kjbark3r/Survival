channel <- odbcDriverConnect("Driver={Microsoft Access Driver (*.mdb, *.accdb)};
dbq=C:/Users/kristin.barker/Documents/NSERP/Databases and Mort Reports/Sapphire_Veg_Database.accdb")
library(RODBC)
library(dplyr)
library(tidyr)
channel <- odbcDriverConnect("Driver={Microsoft Access Driver (*.mdb, *.accdb)};
dbq=C:/Users/kristin.barker/Documents/NSERP/Databases and Mort Reports/Sapphire_Veg_Database.accdb")
classn <- sqlQuery(channel, paste("select * from Classification"))
colnames(classn) <- c("VisitDate", "PlotID", "PlotM", "Species", "Total", "Live", "Senesced")
length(unique(classn$PlotID))
(unique(classn$PlotID))
a <- unique(classn$PlotID)
(arrange(a))
a
a <- as.data.frame(a)
(arrange(a))
View(a)
channel <- odbcDriverConnect("Driver={Microsoft Access Driver (*.mdb, *.accdb)};
dbq=C:/Users/kristin.barker/Documents/NSERP/Databases and Mort Reports/Sapphire_Veg_Phenology.accdb")
phen <- sqlQuery(channel, paste("select * from Classification"))
colnames(phen) <- c("VisitDate", "PlotID", "PlotM", "Species", "Total", "Live", "Senesced")
bio <- classn; rm(classn)
plots.bio <- as.data.frame(unique(bio$PlotID))
rm(a)
plots.phen <- as.data.frame(unique(phen$PlotID))
library(RODBC)
library(dplyr)
#phen
channel <- odbcDriverConnect("Driver={Microsoft Access Driver (*.mdb, *.accdb)};
dbq=C:/Users/kjbark3r/Documents/NSERP/Databases/Sapphire_Veg_Phenology.accdb")
phen <- sqlQuery(channel, paste("select * from Classification"))
colnames(phen) <- c("VisitDate", "PlotID", "PlotM", "Species", "Total", "Live", "Senesced")
phenplots <- as.data.frame(unique(phen$PlotID))
colnames(phenplots) <- "PlotID"
#bio
channel <- odbcDriverConnect("Driver={Microsoft Access Driver (*.mdb, *.accdb)};
dbq=C:/Users/kjbark3r/Documents/NSERP/Databases/Sapphire_Veg_Database_2016-06-28.accdb")
bio <-  sqlQuery(channel, paste("select * from Classification"))
colnames(bio) <- c("VisitDate", "PlotID", "PlotM", "Species", "Total", "Live", "Senesced")
bioplots <- as.data.frame(unique(bio$PlotID))
colnames(bioplots) <- "PlotID"
bioplots
##########################################################
#######   ESTIMATING GRAMS OF DIGESTIBLE MATTER    #######
####   ACROSS NORTH SAPPHIRES IN SIMMER 2014 & 2015   ####
##################    OCT 2016     #######################
##########################################################
###########################
#### Setup             ####
###########################
library(sp) #for kernel centroid estimate
library(adehabitatHR) #for kernel centroid estimate
library(raster)
library(rgdal) #Access geodatabases
library(rgeos)
library(dplyr) #Group by function
library(ggplot2)
library(AICcmodavg)
wd_workcomp <- "C:\\Users\\kristin.barker\\Documents\\GitHub\\Vegetation"
wd_laptop <- "C:\\Users\\kjbark3r\\Documents\\UMT\\Thesis\\Migration_Consequences\\Analyses\\Veg"
if (file.exists(wd_workcomp)) {
setwd(wd_workcomp)
wd <- wd_workcomp
} else {
setwd(wd_laptop)
wd <- wd_laptop
}
rm(wd_workcomp, wd_laptop)
rasterOptions(maxmemory = 1e+09) # increases max number of cells to read into memory, increasing processing time
#################################################################################
##      EITHER RUN THIS SECTION OR PRECEDING SECTION (PROCESSES DATA)          ##
#  Pull in processed data from above section (if you've already run it once) ####
#################################################################################
# plot-level NDVI values
rmt.data <- read.csv("ndvi-plot.csv") %>%
select(PlotVisit, NDVI)
#datafile with the year sampled, GDM per plot, along with plot lat/longs
plot.data <-read.csv("gdm-plot-summer.csv", header=T)  %>%
filter(!PlotVisit == "220.2015-08-03") %>% #remove GDM outlier (landcov also wrong)
left_join(rmt.data, by = "PlotVisit") #add ndvi
#above datafile as shapefile
plots<-readOGR(".", layer ='GDM_plots')
#all rasters for covariates (graciously processed & provided by jesse)
raster_data<-list.files(path=paste(wd, "writtenrasters", sep="/"), pattern="tif$", full.names=TRUE)
s <- stack(raster_data)
names(s)
################################################################################################################################
#Extract attribute data for each plot and write a data.frame for building landscape GDM model ####
################################################################################################################################
# Extract values of rasters to sampling locations and create data.frame with GDM and attributes
ext<-extract(s, plots) ##Extract from raster stack for each plot location
plot.data <- data.frame(plot.data) ##Convert plot info attribute table to dataframe
data <- cbind(plot.data, ext)	%>% ##Bind  plot info and extracted landcover data into df
rename(ndvi = NDVI) ##Follow naming convention
data$Date<-as.Date(data$Date, "%Y-%m-%d") #Set dates and calculate Year
data$Year<-as.numeric(format(data$Date, '%Y'))
#Pick correct years of covariates
data$cover_class <- ifelse(data$Year == 2014, data$esp6_14, data$esp6_15)
data$ndvi_dur <- ifelse(data$Year == 2014, data$ndvi_dur_2014, data$ndvi_dur_2015)
data$ndvi_ti <- ifelse(data$Year == 2014, data$ndvi_ti_2014, data$ndvi_ti_2015)
data$sum_precip <- ifelse(data$Year == 2014, data$precip_2014, data$precip_2015)
#make NDVI durations classified as "NoData" into NAs
data$ndvi_dur <- ifelse(data$ndvi_dur < 90 | data$ndvi_dur > 365, NA, data$ndvi_dur)
#Create new covariates, standardize covariates and finish building dataset
data$cover_class<-as.factor(data$cover_class)
data$cc_std<-((data$cc-(mean(data$cc)))/(sd(data$cc)))
data$cti_std<-((data$cti-(mean(data$cti)))/(sd(data$cti)))
data$elev_std<-((data$elev-(mean(data$elev)))/(sd(data$elev)))
data$hillshade_std<-((data$hillshade-(mean(data$hillshade)))/(sd(data$hillshade)))
data$ndvi_ti_std<-((data$ndvi_ti-(mean(data$ndvi_ti)))/(sd(data$ndvi_ti)))
data$sum_precip_std<-((data$sum_precip-(mean(data$sum_precip)))/(sd(data$sum_precip)))
data$slope_std<-((data$slope-(mean(data$slope)))/(sd(data$slope)))
data$ndvi_std<-((data$ndvi-(mean(data$ndvi)))/(sd(data$ndvi)))
# join to land cover classifications to attach names
clsref_esp <- data.frame(cbind(cover_class = c(1,2,3,4,5,6,7,8,9,10,11,12),
class_name = c("Mesic Forest (Burn >15)", "Dry Forest (Burn >15)", "Grass/Shrub/Open Woodland",
"Dry Ag", "Valley Bottom Riparian","Montane Riparian", "Irrigated Ag",
"Dry Forest Burn 0-5", "Dry Forest Burn 6-15",
"Mesic Forest Burn 0-5", "Mesic Forest Burn 6-15",
"Rx Dry Forest Burn 0-5")))
clsref_esp$cover_class <- as.numeric(as.character(clsref_esp$cover_class))
data <- merge(data, clsref_esp, by="cover_class")
# create subset of data without the "NA" NDVI durations
datasub <- data[!is.na(data$ndvi_dur),]
datasub$ndvi_dur_std<-((datasub$ndvi_dur-(mean(datasub$ndvi_dur)))/(sd(datasub$ndvi_dur)))
dat.GDM <- datasub
dat.GDM$cover_class<-as.factor(dat.GDM$cover_class)
## order by inc'ing median GDM and set that as reference level order for model
cov.gdm <- dat.GDM %>%
dplyr::select(c(cover_class, class_name, GDM)) %>%
group_by(class_name, cover_class) %>%
summarise(MedGDM = median(GDM)) %>%
arrange(MedGDM)
lev <- as.vector(cov.gdm$cover_class)
dat.GDM$cover_class <- factor(dat.GDM$cover_class, levels = lev)
m1 <-
m.all <- glm(log(GDM) ~ cover_class + cti_std + elev_std + hillshade_std + ndvi_dur_std + ndvi_ti_std + sum_precip_std + slope_std + ndvi_std, family = gaussian(link=identity), data=dat.GDM)
summary(m.all)
plot(log(GDM) ~ cover_class + cti_std + elev_std + ndvi_ti_std + slope_std + ndvi_std, family = gaussian(link=identity), data=dat.GDM)
plot(log(GDM) ~ cover_class + cti_std + elev_std + ndvi_ti_std + slope_std + ndvi_std, data=dat.GDM)
m.all <- glm(log(GDM) ~ cover_class + cti_std + elev_std + hillshade_std + ndvi_dur_std + ndvi_ti_std + sum_precip_std + slope_std + ndvi_std, family = gaussian(link=identity), data=dat.GDM)
step <- stepAIC(m.all, direction="both")
step$anova  # display results
library(leaps)
leaps<-regsubsets(log(GDM) ~ cover_class + cti_std + elev_std + hillshade_std + ndvi_dur_std + ndvi_ti_std + sum_precip_std + slope_std + ndvi_std,data=dat.GDM,nbest=3)
a <- summary(leaps)
names(summary(leaps))
arrange(summary(leaps) $adjr2)
a <- summary(leaps) $adjr2
(arrange(a))
summary(leaps) $adjr2
a <- as.data.frame(summary(leaps) $adjr2)
(arrange(a))
(arrange(desc(a)))
summary(a$rsq)
a <- summary(leaps)
summary(a$rsq)
str(a)
names(summary(leaps))
b <- cbind(a$call, a$adjr2)
View(b)
b <- cbind(a$call, a$which)
View(b)
b <- cbind(a$call, a$adjr2)
View(b)
b <- cbind(c(a$call, a$adjr2))
View(b)
eff <- data.frame(nrow = 2, ncol = ncol(a))
eff <- data.frame(nrow = nrow(a), ncol = 2)
eff <- matrix(nrow = nrow(a), ncol = 2)
eff <- data.frame(nrow = nrow(leaps), ncol = 2)
nrow(leaps)
nrow(a)
eff <- data.frame(nrow = 24, ncol = 2)
eff[,1] <- a$adjr2
eff <- matrix(nrow = 24, ncol = 2)
eff[,1] <- a$adjr2
eff[,2] <- a$call
eff[,2] <- a$which
names(a)
a
##############################
## misc code related to
## survival consequences of varying mig behavs
### kjb nov 2016
##############################
## SETUP ####
## WD
wd_workcomp <- "C:\\Users\\kristin.barker\\Documents\\GitHub\\Survival"
wd_laptop <- "C:\\Users\\kjbark3r\\Documents\\GitHub\\Survival"
if (file.exists(wd_workcomp)) {
setwd(wd_workcomp)
} else {
if(file.exists(wd_laptop)) {
setwd(wd_laptop)
} else {
cat("Are you SURE you got that file path right?\n")
}
}
rm(wd_workcomp, wd_laptop)
## libraries
library(dplyr)
library(adehabitatHR) # needed?
library(raster)
## read in data (already subsetted to females only)
rawdata <- read.csv("../Migration/HRoverlap/volumeintersection.csv")
## DISCRETIZING ####
## categorize individuals (and rank, for funzies)
mig <- rawdata %>%
select(-FallVI) %>%
rename(VI = SprVI) %>%
transform(Rank = rank(-VI, ties.method = "random")) %>%
transform(Mig = ifelse(VI >= 0.5, "Resident",
ifelse(VI == 0, "Migrant",
"Intermediate")))
## visualize
test <- raster("../zOld/Migration/KDE140040-S15.tif")
test2 <- getverticeshr(test) # newp
?getverticeshr
?estUD
test2 <- kernelUD(test)
str(test)
test2 <- SpatialPointsDataFrame(test)
mig <- rawdata %>%
test2 <- getverticeshr("../zOld/Migration/KDE140040-S15.tif")
str(test)
test[,1]
?kernelUD
?kernel.area
pts.w <- list.files("../zOld/Migration", pattern = "Pts.*-[Ww].*\\.shp$")
pts.s <- list.files("../zOld/Migration", pattern = "Pts.*-[Ss].*\\.shp$")
######################################################
## Migration - Volume Overlap Calculations ##
########  NSERP - Kristin Barker - June 2016  ########
######################################################
##SET WD
####Work computer, personal laptop, or external hard drive
wd_workcomp <- "C:\\Users\\kristin.barker\\Documents\\GitHub\\Survival"
wd_laptop <- "C:\\Users\\kjbark3r\\Documents\\GitHub\\Survival"
wd_external <- "E:\\Kristins\\Survival\\"
if (file.exists(wd_workcomp)) {
setwd(wd_workcomp)
} else {
if(file.exists(wd_laptop)) {
setwd(wd_laptop)
} else {
if(file.exists(wd_external)) {
setwd(wd_external)
} else {
cat("Are you SURE you got that file path right?\n")
}
}
}
rm(wd_workcomp, wd_laptop, wd_external)
##LOAD PACKAGES
library(sp) #for kernel centroid estimate
library(adehabitatHR) #for kernel centroid estimate
library(raster) #prob don't need this one here
library(rgdal) #for latlong/stateplane conversions
library(gsubfn)
library(maptools) #for writeSpatialShape
library(dplyr) #for joins
###########################################################################################
#SET UP DATA
###########################################################################################
#GPS DATA FROM COLLARS, PLUS MIGRATION SEASON/YEAR
locs <- read.csv("./Migration/HRoverlap/collardata-locsonly-equalsampling.csv", as.is = TRUE, header = TRUE)
locs$Date <- as.Date(locs$Date, "%Y-%m-%d")
locs <- read.csv("../Migration/HRoverlap/collardata-locsonly-equalsampling.csv", as.is = TRUE, header = TRUE)
locs$Date <- as.Date(locs$Date, "%Y-%m-%d")
# delineate winter and summer HRs
locs$MigHR <- ifelse(between(locs$Date, as.Date("2014-01-01"), as.Date("2014-03-15")), "Winter",
ifelse(between(locs$Date, as.Date("2014-07-01"), as.Date("2014-08-31")), "Summer",
ifelse(between(locs$Date, as.Date("2015-01-01"), as.Date("2015-03-15")), "Winter",
ifelse(between(locs$Date, as.Date("2015-07-01"), as.Date("2015-08-31")), "Summer",
ifelse(between(locs$Date, as.Date("2016-01-01"), as.Date("2016-03-15")), "Winter",
ifelse(NA))))))
locs$IndivYr <- ifelse(locs$Date < "2015-01-01",
paste(locs$AnimalID, "-14", sep=""),
paste(locs$AnimalID, "-15", sep=""))
# write.csv(locs, file = "locsMigHR3.csv", row.names = FALSE)
View(locs)
unique(locs$MigHR)
indivyrs <- as.data.frame(unique(locs$IndivYr))
numelk.spr14 <- nrow(indivyrs)
#DEFINE PROJECTIONS
latlong <- CRS("+init=epsg:4326")
stateplane <- CRS("+init=epsg:2818")
?kerneloverlap
View(puechabonsp)
elk <- "140040-14"
temp_dat <- subset(locs, AnimalID == elk)
temp_dat <- subset(temp_dat, MigHR == "Winter")
temp_dat <- subset(locs, AnimalID == elk)
temp_dat <- subset(locs, IndivYr == elk)
temp_dat <- subset(temp_dat, MigHR == "Winter")
#Get xy points, write to dataframe, to spatial data frame, to stateplane projection
xy <- data.frame("x"=temp_dat$Long,"y"=temp_dat$Lat)
xy.spdf.ll <- SpatialPointsDataFrame(xy, temp_dat, proj4string = latlong)
xy.spdf.sp <- spTransform(xy.spdf.ll,stateplane)
xy.spdf.sp[,22]
win <- subset(locs, MigHR == "Winter")
xy.spdf.sp[,25]
xy.spdf.sp[,23]
######################################################
## Migration - Volume Overlap Calculations ##
########  NSERP - Kristin Barker - June 2016  ########
######################################################
##SET WD
####Work computer, personal laptop, or external hard drive
wd_workcomp <- "C:\\Users\\kristin.barker\\Documents\\GitHub\\Survival"
wd_laptop <- "C:\\Users\\kjbark3r\\Documents\\GitHub\\Survival"
wd_external <- "E:\\Kristins\\Survival\\"
if (file.exists(wd_workcomp)) {
setwd(wd_workcomp)
} else {
if(file.exists(wd_laptop)) {
setwd(wd_laptop)
} else {
if(file.exists(wd_external)) {
setwd(wd_external)
} else {
cat("Are you SURE you got that file path right?\n")
}
}
}
rm(wd_workcomp, wd_laptop, wd_external)
##LOAD PACKAGES
library(sp) #for kernel centroid estimate
library(adehabitatHR) #for kernel centroid estimate
library(raster) #prob don't need this one here
library(rgdal) #for latlong/stateplane conversions
library(gsubfn)
library(maptools) #for writeSpatialShape
library(dplyr) #for joins
###########################################################################################
#SET UP DATA
###########################################################################################
#GPS DATA FROM COLLARS, PLUS MIGRATION SEASON/YEAR
locs <- read.csv("../Migration/HRoverlap/collardata-locsonly-equalsampling.csv", as.is = TRUE, header = TRUE)
locs$Date <- as.Date(locs$Date, "%Y-%m-%d")
# delineate winter and summer HRs
locs$MigHR <- ifelse(between(locs$Date, as.Date("2014-01-01"), as.Date("2014-03-15")), "Winter",
ifelse(between(locs$Date, as.Date("2014-07-01"), as.Date("2014-08-31")), "Summer",
ifelse(between(locs$Date, as.Date("2015-01-01"), as.Date("2015-03-15")), "Winter",
ifelse(between(locs$Date, as.Date("2015-07-01"), as.Date("2015-08-31")), "Summer",
ifelse(between(locs$Date, as.Date("2016-01-01"), as.Date("2016-03-15")), "Winter",
ifelse(NA))))))
locs$IndivYr <- ifelse(locs$Date < "2015-01-01",
paste(locs$AnimalID, "-14", sep=""),
paste(locs$AnimalID, "-15", sep=""))
#LIST OF ANIMALS TO RUN
#indivyrs <- as.data.frame(unique(locs$IndivYr))
#numelk <- nrow(indivyrs)
#DEFINE PROJECTIONS
latlong <- CRS("+init=epsg:4326")
stateplane <- CRS("+init=epsg:2818")
win <- subset(locs, MigHR == "Winter")
xy <- data.frame("x"=win$Long,"y"=win$Lat)
xy.spdf.ll <- SpatialPointsDataFrame(xy, win, proj4string = latlong)
xy.spdf.sp <- spTransform(xy.spdf.ll,stateplane)
kuds <- kernelUD(xy.spdf.sp[,23], h = "href", same4all = FALSE)
hr <- getverticeshr(kuds)
hrs <- getverticeshr(kuds)
rm(hr)
win.a <- sapply(slot(hrs, "polygons"), slot, "area")
mean(win.a)
sum <- subset(locs, MigHR == "Summer")
xy <- data.frame("x"=sum$Long,"y"=sum$Lat)
xy.spdf.ll <- SpatialPointsDataFrame(xy, sum, proj4string = latlong)
xy.spdf.sp <- spTransform(xy.spdf.ll,stateplane)
kuds <- kernelUD(xy.spdf.sp[,23], h = "href", same4all = FALSE)
hrs <- getverticeshr(kuds)
sum.a <- sapply(slot(hrs, "polygons"), slot, "area")
mean(sum.a)
mean(sum.a)/mean(win.a)
mean(win.a)/mean(sum.a)
median(sum.a)
median(win.a)
median(sum.a)/median(win.a)
median(win.a)/median(sum.a)
median(win.a)/median(sum.a)
## categorize individuals (and rank, for funzies)
mig <- rawdata %>%
select(-FallVI) %>%
rename(VI = SprVI) %>%
transform(Rank = rank(-VI, ties.method = "average")) %>%
transform(Mig = ifelse(VI >= 0.65, "Resident",
ifelse(VI == 0, "Migrant",
"Intermediate")))
######################################################
#### SURVIVAL consequences of migratory behaviors ####
########  NSERP - Kristin Barker - Nov 2016   ########
######################################################
## WD
wd_workcomp <- "C:\\Users\\kristin.barker\\Documents\\GitHub\\Survival"
wd_laptop <- "C:\\Users\\kjbark3r\\Documents\\GitHub\\Survival"
if (file.exists(wd_workcomp)) {
setwd(wd_workcomp)
} else {
if(file.exists(wd_laptop)) {
setwd(wd_laptop)
} else {
cat("Are you SURE you got that file path right?\n")
}
}
rm(wd_workcomp, wd_laptop)
## libraries
library(dplyr)
## read in data (already subsetted to females only)
rawdata <- read.csv("../Migration/HRoverlap/volumeintersection.csv")
## categorize individuals (and rank, for funzies)
mig <- rawdata %>%
select(-FallVI) %>%
rename(VI = SprVI) %>%
transform(Rank = rank(-VI, ties.method = "average")) %>%
transform(Mig = ifelse(VI >= 0.65, "Resident",
ifelse(VI == 0, "Migrant",
"Intermediate")))
######################################################
#### SURVIVAL consequences of migratory behaviors ####
########  NSERP - Kristin Barker - Nov 2016   ########
######################################################
## WD
wd_workcomp <- "C:\\Users\\kristin.barker\\Documents\\GitHub\\Survival"
wd_laptop <- "C:\\Users\\kjbark3r\\Documents\\GitHub\\Survival"
if (file.exists(wd_workcomp)) {
setwd(wd_workcomp)
} else {
if(file.exists(wd_laptop)) {
setwd(wd_laptop)
} else {
cat("Are you SURE you got that file path right?\n")
}
}
rm(wd_workcomp, wd_laptop)
## libraries
library(dplyr)
## read in data (already subsetted to females only)
rawdata <- read.csv("../Migration/HRoverlap/volumeintersection.csv")
## categorize individuals (and rank, for funzies)
mig <- rawdata %>%
dplyr:select(-FallVI) %>%
rename(VI = SprVI) %>%
transform(Rank = rank(-VI, ties.method = "average")) %>%
transform(Mig = ifelse(VI >= 0.65, "Resident",
ifelse(VI == 0, "Migrant",
"Intermediate")))
######################################################
#### SURVIVAL consequences of migratory behaviors ####
########  NSERP - Kristin Barker - Nov 2016   ########
######################################################
## WD
wd_workcomp <- "C:\\Users\\kristin.barker\\Documents\\GitHub\\Survival"
wd_laptop <- "C:\\Users\\kjbark3r\\Documents\\GitHub\\Survival"
if (file.exists(wd_workcomp)) {
setwd(wd_workcomp)
} else {
if(file.exists(wd_laptop)) {
setwd(wd_laptop)
} else {
cat("Are you SURE you got that file path right?\n")
}
}
rm(wd_workcomp, wd_laptop)
## libraries
library(dplyr)
## read in data (already subsetted to females only)
rawdata <- read.csv("../Migration/HRoverlap/volumeintersection.csv")
## categorize individuals (and rank, for funzies)
mig <- rawdata %>%
dplyr::select(-FallVI) %>%
rename(VI = SprVI) %>%
transform(Rank = rank(-VI, ties.method = "average")) %>%
transform(Mig = ifelse(VI >= 0.65, "Resident",
ifelse(VI == 0, "Migrant",
"Intermediate")))
length(which(mig$Mig == "Resident")) # nope nope nope
mig <- rawdata %>%
dplyr::select(-FallVI) %>%
rename(VI = SprVI) %>%
transform(Rank = rank(-VI, ties.method = "average")) %>%
transform(Mig = ifelse(VI >= 0.35, "Resident",
ifelse(VI == 0, "Migrant",
"Intermediate")))
length(which(mig$Mig == "Resident")) # nope nope nope
length(which(mig$Mig == "Migrant")) # still feel ok about this one
length(which(mig$Mig == "Intermediate"))
